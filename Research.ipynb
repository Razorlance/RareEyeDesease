{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnAKB3B01n9s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterGrid\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_recall_curve, roc_curve, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_ctgan_synthesizer(data, epochs=300, verbose=False):\n",
        "    metadata = SingleTableMetadata()\n",
        "    metadata.detect_from_dataframe(data)\n",
        "    synthesizer = CTGANSynthesizer(metadata=metadata, epochs=epochs, verbose=verbose)\n",
        "    synthesizer.fit(data)\n",
        "    return synthesizer"
      ],
      "metadata": {
        "id": "NT7yOx6d4F4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aniridia_df = pd.read_excel(\"2025-04-11 Aniridiia oftal'molog.xlsx\")\n",
        "albinism_df = pd.read_excel(\"2025-04-11 Al'binizm oftal'molog.xlsx\")\n"
      ],
      "metadata": {
        "id": "ttTzSi964DSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_age_to_years(age_str):\n",
        "    if pd.isna(age_str):\n",
        "        return np.nan\n",
        "    s = str(age_str).lower().replace(',', '.').strip()\n",
        "    if 'mes' in s or 'мес' in s:\n",
        "        digits = ''.join(ch for ch in s if ch.isdigit())\n",
        "        if digits:\n",
        "            return int(digits) / 12.0\n",
        "        else:\n",
        "            return np.nan\n",
        "    if 'год' in s or 'лет' in s or 'года' in s:\n",
        "        nums = [int(x) for x in s.split() if x.isdigit()]\n",
        "        if len(nums) == 0:\n",
        "            return np.nan\n",
        "        if len(nums) == 1:\n",
        "            return float(nums[0])\n",
        "        if len(nums) >= 2:\n",
        "            years = float(nums[0]); months = float(nums[1])\n",
        "            if years < 0: years = 0\n",
        "            if months < 0: months = 0\n",
        "            return years + months/12.0\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return np.nan"
      ],
      "metadata": {
        "id": "3YZbhqm4389q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(df, disease_type):\n",
        "    \"\"\"\n",
        "    Preprocess aniridia or albinism dataframe:\n",
        "    \"\"\"\n",
        "    result = pd.DataFrame()\n",
        "    # Age\n",
        "    if 'Возраст пациента' in df.columns or 'Возраст' in ' '.join(df.columns):\n",
        "        age_col = 'Возраст пациента' if 'Возраст пациента' in df.columns else 'Возраст'\n",
        "        result['Age'] = df[age_col].apply(parse_age_to_years)\n",
        "    else:\n",
        "        result['Age'] = np.nan\n",
        "    # Sex (Male = 1, Female = 0)\n",
        "    if 'Пол' in df.columns:\n",
        "        result['Sex_Male'] = df['Пол'].map({'М': 1, 'Ж': 0})\n",
        "    else:\n",
        "        result['Sex_Male'] = np.nan\n",
        "    # Nystagmus (Yes=1, No=0)\n",
        "    nyst_col = None\n",
        "    for col in df.columns:\n",
        "        if 'нистагм' in str(col).lower():\n",
        "            nyst_col = col; break\n",
        "    if nyst_col:\n",
        "        result['Nystagmus'] = df[nyst_col].map({'Да': 1, 'Нет': 0})\n",
        "    else:\n",
        "        result['Nystagmus'] = np.nan\n",
        "    # Photophobia (light sensitivity)\n",
        "    photo_col = None\n",
        "    for col in df.columns:\n",
        "        if 'светобоязнь' in str(col).lower():\n",
        "            photo_col = col; break\n",
        "    if photo_col:\n",
        "        result['Photophobia'] = df[photo_col].map({'Да': 1, 'Нет': 0})\n",
        "    else:\n",
        "        result['Photophobia'] = 0 if disease_type == 'albinism' else np.nan\n",
        "    # Cataract (Yes=1, No=0)\n",
        "    cat_col = None\n",
        "    for col in df.columns:\n",
        "        if 'катаракта' in str(col).lower() and 'пациента' in str(col).lower():\n",
        "            cat_col = col; break\n",
        "    if cat_col:\n",
        "        result['Cataract'] = df[cat_col].map({'Да': 1, 'Нет': 0})\n",
        "    else:\n",
        "        result['Cataract'] = np.nan\n",
        "    # Genetic test done (Yes=1, No=0)\n",
        "    gen_col = None\n",
        "    for col in df.columns:\n",
        "        if 'молекулярно' in str(col) and 'Да' in str(col):\n",
        "            gen_col = col; break\n",
        "    if gen_col:\n",
        "        result['GeneticTestDone'] = df[gen_col].fillna('Нет').map(lambda x: 1 if x == 'Да' else 0)\n",
        "    else:\n",
        "        result['GeneticTestDone'] = np.nan\n",
        "    # Uses assistive device (Yes=1, No=0)\n",
        "    rehab_col = None\n",
        "    for col in df.columns:\n",
        "        if 'реабилитац' in str(col).lower():\n",
        "            rehab_col = col; break\n",
        "    if rehab_col:\n",
        "        result['UsesDevice'] = df[rehab_col].map({'Да': 1, 'Нет': 0})\n",
        "    else:\n",
        "        result['UsesDevice'] = np.nan\n",
        "    # Glaucoma (Yes=1, No=0)\n",
        "    gl_col = None\n",
        "    for col in df.columns:\n",
        "        if 'глаукома' in str(col).lower() and 'пациента' in str(col).lower():\n",
        "            gl_col = col; break\n",
        "    if gl_col:\n",
        "        result['Glaucoma'] = df[gl_col].map({'Да': 1, 'Нет': 0})\n",
        "    else:\n",
        "        result['Glaucoma'] = np.nan\n",
        "    syndrome_label = []\n",
        "    for _, row in df.iterrows():\n",
        "        label = 'None'\n",
        "        notes_text = ''\n",
        "        for col in df.columns:\n",
        "            if ('екомендации' in str(col)) or ('заметки' in str(col)) or ('рекомендации' in str(col).lower()):\n",
        "                notes_text = str(row[col]).lower(); break\n",
        "        if disease_type == 'aniridia':\n",
        "            if 'wagr' in notes_text or 'вагр' in notes_text:\n",
        "                label = 'WAGR'\n",
        "        elif disease_type == 'albinism':\n",
        "            if 'hps' in notes_text or 'hermansky' in notes_text or 'гепат' in notes_text or 'пудлак' in notes_text:\n",
        "                label = 'HPS'\n",
        "        syndrome_label.append(label)\n",
        "    result['SyndromeLabel'] = syndrome_label\n",
        "    result['DiseaseType'] = disease_type\n",
        "    return result"
      ],
      "metadata": {
        "id": "_bZ5hmi437EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proc_aniridia = preprocess_dataset(aniridia_df, disease_type='aniridia')\n",
        "proc_albinism = preprocess_dataset(albinism_df, disease_type='albinism')"
      ],
      "metadata": {
        "id": "5x4mIg0x3yNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([proc_aniridia, proc_albinism], ignore_index=True)\n",
        "\n",
        "combined_df['Age'].fillna(combined_df['Age'].median(), inplace=True)\n",
        "proc_aniridia['Age'].fillna(proc_aniridia['Age'].median(), inplace=True)\n",
        "proc_albinism['Age'].fillna(proc_albinism['Age'].median(), inplace=True)\n",
        "\n",
        "for feature in ['Sex_Male', 'Nystagmus', 'Photophobia', 'Cataract', 'GeneticTestDone']:\n",
        "    combined_df[feature].fillna(0, inplace=True)\n",
        "    proc_aniridia[feature].fillna(0, inplace=True)\n",
        "    proc_albinism[feature].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "78M0UYOG3upQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glaucoma_features = ['Age', 'Sex_Male', 'Nystagmus', 'Cataract', 'GeneticTestDone']\n",
        "device_features   = ['Age', 'Sex_Male', 'Nystagmus', 'Photophobia', 'GeneticTestDone']\n",
        "combined_df['DiseaseType'] = combined_df['DiseaseType'].map({'aniridia': 0, 'albinism': 1})\n",
        "syndrome_features = ['Age', 'Sex_Male', 'Nystagmus', 'Photophobia', 'Cataract', 'GeneticTestDone', 'DiseaseType']\n",
        "\n",
        "gl_mask = ~pd.isna(proc_aniridia['Glaucoma'])\n",
        "X_glaucoma = proc_aniridia.loc[gl_mask, glaucoma_features].values\n",
        "y_glaucoma = proc_aniridia.loc[gl_mask, 'Glaucoma'].astype(int).values\n",
        "\n",
        "dev_mask = ~pd.isna(proc_albinism['UsesDevice'])\n",
        "X_device = proc_albinism.loc[dev_mask, device_features].values\n",
        "y_device = proc_albinism.loc[dev_mask, 'UsesDevice'].astype(int).values\n",
        "\n",
        "X_syndrome = combined_df[syndrome_features].values\n",
        "y_syndrome = combined_df['SyndromeLabel'].map({'None':0, 'WAGR':1, 'HPS':2}).values"
      ],
      "metadata": {
        "id": "nrp5AxRu3qln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(proc_aniridia['Age'], label='Aniridia', color='blue', kde=True, stat=\"density\")\n",
        "sns.histplot(proc_albinism['Age'], label='Albinism', color='orange', kde=True, stat=\"density\")\n",
        "plt.legend()\n",
        "plt.title(\"Age distribution by disease type\")\n",
        "plt.xlabel(\"Age (years)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()\n",
        "\n",
        "binary_features = ['Nystagmus', 'Photophobia', 'Cataract', 'GeneticTestDone', 'UsesDevice']\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12,6))\n",
        "axes = axes.flatten()\n",
        "for i, feat in enumerate(binary_features):\n",
        "    if feat not in combined_df.columns:\n",
        "        continue\n",
        "    sns.countplot(x=combined_df[feat].fillna(0).astype(int), ax=axes[i])\n",
        "    axes[i].set_title(f\"{feat} (0=No, 1=Yes)\")\n",
        "    axes[i].set_xlabel(\"\")\n",
        "axes[-1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
        "\n",
        "axes[0].bar(['No Glaucoma','Glaucoma'], [np.sum(y_glaucoma==0), np.sum(y_glaucoma==1)])\n",
        "axes[0].set_title(\"Glaucoma (Aniridia)\")\n",
        "\n",
        "axes[1].bar(['No Device','Uses Device'], [np.sum(y_device==0), np.sum(y_device==1)])\n",
        "axes[1].set_title(\"Device (Albinism)\")\n",
        "\n",
        "counts_synd = [np.sum(y_syndrome==0), np.sum(y_syndrome==1), np.sum(y_syndrome==2)]\n",
        "axes[2].bar(['None','WAGR','HPS'], counts_synd)\n",
        "axes[2].set_title(\"Syndrome classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "logreg_params = {'C': [0.1, 1, 10], 'class_weight': [None, 'balanced'], 'max_iter': [1000]}\n",
        "rf_params     = {'n_estimators': [100], 'max_depth': [None, 5, 10], 'min_samples_leaf': [1, 2, 5]}\n",
        "xgb_params    = {'n_estimators': [100], 'max_depth': [3, 6], 'learning_rate': [0.1],\n",
        "                 'use_label_encoder': [False], 'eval_metric': ['logloss']}\n"
      ],
      "metadata": {
        "id": "828Tzsik3oOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(X, y, model_type='binary'):\n",
        "    \"\"\"\n",
        "    Train Logistic Regression, Random Forest, XGBoost with CV grid search.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    best_models = {}\n",
        "    results = {}\n",
        "    models = [\n",
        "        ('LogReg', LogisticRegression(solver='liblinear'), logreg_params),\n",
        "        ('RandomForest', RandomForestClassifier(random_state=42), rf_params),\n",
        "        ('XGBoost', XGBClassifier(objective='multi:softprob', num_class=3, random_state=42, use_label_encoder=False, eval_metric='mlogloss'), xgb_params)\n",
        "    ]\n",
        "    for name, model, param_grid in models:\n",
        "        best_score = -np.inf\n",
        "        best_params = None\n",
        "        for params in ParameterGrid(param_grid):\n",
        "            model.set_params(**params)\n",
        "            scores = []\n",
        "            for train_idx, val_idx in skf.split(X, y):\n",
        "                X_train, X_val = X[train_idx], X[val_idx]\n",
        "                y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "                if model_type == 'multi':\n",
        "                    train_df = pd.DataFrame(X_train, columns=syndrome_features)\n",
        "                    train_df['y'] = y_train\n",
        "                    if any(y_train == 1):\n",
        "                        wagr_data = train_df[train_df['y'] == 1].drop('y', axis=1)\n",
        "                        if len(wagr_data) >= 2:\n",
        "                            ctgan_wagr = fit_ctgan_synthesizer(wagr_data)\n",
        "                            syn_wagr = ctgan_wagr.sample(max(0, 20 - len(wagr_data)))\n",
        "                            if not syn_wagr.empty:\n",
        "                                syn_wagr['y'] = 1\n",
        "                                train_df = pd.concat([train_df, syn_wagr], ignore_index=True)\n",
        "                    if any(y_train == 2):\n",
        "                        hps_data = train_df[train_df['y'] == 2].drop('y', axis=1)\n",
        "                        if len(hps_data) >= 2:\n",
        "                            ctgan_hps = fit_ctgan_synthesizer(hps_data)\n",
        "                            syn_hps = ctgan_hps.sample(max(0, 20 - len(hps_data)))\n",
        "                            if not syn_hps.empty:\n",
        "                                syn_hps['y'] = 2\n",
        "                                train_df = pd.concat([train_df, syn_hps], ignore_index=True)\n",
        "                    y_train = train_df['y'].astype(int).values\n",
        "                    X_train = train_df.drop('y', axis=1).values\n",
        "\n",
        "                elif model_type == 'binary_imbalanced':\n",
        "                    train_df = pd.DataFrame(X_train, columns=device_features)\n",
        "                    train_df['y'] = y_train\n",
        "                    if any(y_train == 1):\n",
        "                        pos_data = train_df[train_df['y'] == 1].drop('y', axis=1)\n",
        "                        if len(pos_data) > 0:\n",
        "                            ctgan_pos = fit_ctgan_synthesizer(pos_data)\n",
        "                            syn_pos = ctgan_pos.sample(2 * len(pos_data))\n",
        "                            if not syn_pos.empty:\n",
        "                                syn_pos['y'] = 1\n",
        "                                train_df = pd.concat([train_df, syn_pos], ignore_index=True)\n",
        "                    y_train = train_df['y'].astype(int).values\n",
        "                    X_train = train_df.drop('y', axis=1).values\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                if model_type == 'multi':\n",
        "                    y_pred = model.predict(X_val)\n",
        "                    score = f1_score(y_val, y_pred, average='macro')\n",
        "                else:\n",
        "                    if hasattr(model, \"predict_proba\"):\n",
        "                        y_score = model.predict_proba(X_val)[:, 1]\n",
        "                    else:\n",
        "                        try:\n",
        "                            y_score = model.decision_function(X_val)\n",
        "                        except AttributeError:\n",
        "                            y_score = model.predict(X_val)\n",
        "                    if len(np.unique(y_val)) < 2:\n",
        "                        continue\n",
        "                    score = roc_auc_score(y_val, y_score)\n",
        "                scores.append(score)\n",
        "            avg_score = np.mean(scores) if scores else -np.inf\n",
        "            if avg_score > best_score:\n",
        "                best_score = avg_score\n",
        "                best_params = params\n",
        "        best_model = model.__class__(**best_params)\n",
        "        best_model.fit(X, y)\n",
        "        best_models[name] = best_model\n",
        "        results[name] = {'best_params': best_params, 'cv_score': best_score}\n",
        "        print(f\"{name} best CV score: {best_score:.3f} with params {best_params}\")\n",
        "    return best_models, results"
      ],
      "metadata": {
        "id": "rHBsmV1q3ZjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training models for Glaucoma Prediction...\")\n",
        "best_models_glaucoma, cv_results_glaucoma = train_and_evaluate(X_glaucoma, y_glaucoma, model_type='binary')\n",
        "print(\"\\nTraining models for Device Need Prediction...\")\n",
        "best_models_device, cv_results_device = train_and_evaluate(X_device, y_device, model_type='binary_imbalanced')\n",
        "print(\"\\nTraining models for Syndromic Classification...\")\n",
        "best_models_syndrome, cv_results_syndrome = train_and_evaluate(X_syndrome, y_syndrome, model_type='multi')"
      ],
      "metadata": {
        "id": "FtChvrnd3Xfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xg_train, Xg_test, yg_train, yg_test = train_test_split(X_glaucoma, y_glaucoma, test_size=0.2, stratify=y_glaucoma, random_state=1)\n",
        "Xd_train, Xd_test, yd_train, yd_test = train_test_split(X_device, y_device, test_size=0.2, stratify=y_device, random_state=1)\n",
        "Xs_train, Xs_test, ys_train, ys_test = train_test_split(X_syndrome, y_syndrome, test_size=0.2, stratify=y_syndrome, random_state=1)\n",
        "\n",
        "model_g = best_models_glaucoma['XGBoost']\n",
        "model_d = best_models_device['XGBoost']\n",
        "model_s = best_models_syndrome['XGBoost']\n",
        "\n",
        "y_proba_g = model_g.predict_proba(Xg_test)[:, 1]\n",
        "y_pred_g = model_g.predict(Xg_test)\n",
        "print(\"\\nGlaucoma Test ROC-AUC:\", roc_auc_score(yg_test, y_proba_g))\n",
        "print(\"Glaucoma Test PR-AUC:\", average_precision_score(yg_test, y_proba_g))\n",
        "print(\"Glaucoma Test Macro-F1:\", f1_score(yg_test, y_pred_g, average='macro'))\n",
        "\n",
        "y_proba_d = model_d.predict_proba(Xd_test)[:, 1]\n",
        "y_pred_d = model_d.predict(Xd_test)\n",
        "print(\"\\nDevice Test ROC-AUC:\", roc_auc_score(yd_test, y_proba_d))\n",
        "print(\"Device Test PR-AUC:\", average_precision_score(yd_test, y_proba_d))\n",
        "print(\"Device Test Macro-F1:\", f1_score(yd_test, y_pred_d, average='macro'))\n",
        "\n",
        "y_pred_s = model_s.predict(Xs_test)\n",
        "print(\"\\nSyndrome Test Macro-F1:\", f1_score(ys_test, y_pred_s, average='macro'))\n",
        "print(\"Test set classification report (Syndrome):\")\n",
        "print(classification_report(ys_test, y_pred_s, target_names=['None', 'WAGR', 'HPS']))"
      ],
      "metadata": {
        "id": "XRlZxNNq3SjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for name, mdl in best_models_glaucoma.items():\n",
        "    if hasattr(mdl, \"predict_proba\"):\n",
        "        y_score = mdl.predict_proba(Xg_test)[:, 1]\n",
        "    else:\n",
        "        try:\n",
        "            y_score = mdl.decision_function(Xg_test)\n",
        "        except AttributeError:\n",
        "            y_score = mdl.predict(Xg_test)\n",
        "    fpr, tpr, _ = roc_curve(yg_test, y_score)\n",
        "    plt.plot(fpr, tpr, label=name)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Glaucoma Prediction (Test Set)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(yd_test, y_proba_d)\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=\"XGBoost\")\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve - Device Need Prediction (Test Set)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "cm_g = confusion_matrix(yg_test, y_pred_g)\n",
        "cm_d = confusion_matrix(yd_test, y_pred_d)\n",
        "cm_s = confusion_matrix(ys_test, y_pred_s)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "sns.heatmap(cm_g, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0], cbar=False,\n",
        "            xticklabels=[\"No Glaucoma\", \"Glaucoma\"], yticklabels=[\"No Glaucoma\", \"Glaucoma\"])\n",
        "axes[0].set_title(\"Glaucoma Confusion Matrix\"); axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "sns.heatmap(cm_d, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1], cbar=False,\n",
        "            xticklabels=[\"No Device\", \"Uses Device\"], yticklabels=[\"No Device\", \"Uses Device\"])\n",
        "axes[1].set_title(\"Device Need Confusion Matrix\"); axes[1].set_xlabel(\"Predicted\"); axes[1].set_ylabel(\"Actual\")\n",
        "\n",
        "sns.heatmap(cm_s, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[2], cbar=False,\n",
        "            xticklabels=[\"None\", \"WAGR\", \"HPS\"], yticklabels=[\"None\", \"WAGR\", \"HPS\"])\n",
        "axes[2].set_title(\"Syndrome Classification Confusion Matrix\"); axes[2].set_xlabel(\"Predicted\"); axes[2].set_ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "importances_g = model_g.feature_importances_\n",
        "plt.figure()\n",
        "order = np.argsort(importances_g)[::-1]\n",
        "plt.bar(range(len(importances_g)), importances_g[order])\n",
        "plt.xticks(range(len(importances_g)), [glaucoma_features[i] for i in order], rotation=45)\n",
        "plt.ylabel(\"Importance\"); plt.title(\"Feature Importances - Glaucoma (XGBoost)\")\n",
        "plt.show()\n",
        "\n",
        "importances_d = model_d.feature_importances_\n",
        "plt.figure()\n",
        "order = np.argsort(importances_d)[::-1]\n",
        "plt.bar(range(len(importances_d)), importances_d[order], color='orange')\n",
        "plt.xticks(range(len(importances_d)), [device_features[i] for i in order], rotation=45)\n",
        "plt.ylabel(\"Importance\"); plt.title(\"Feature Importances - Device Need (XGBoost)\")\n",
        "plt.show()\n",
        "\n",
        "importances_s = model_s.feature_importances_\n",
        "plt.figure()\n",
        "order = np.argsort(importances_s)[::-1]\n",
        "plt.bar(range(len(importances_s)), importances_s[order], color='green')\n",
        "plt.xticks(range(len(importances_s)), [syndrome_features[i] for i in order], rotation=45)\n",
        "plt.ylabel(\"Importance\"); plt.title(\"Feature Importances - Syndrome Classification (XGBoost)\")\n",
        "plt.show()\n",
        "\n",
        "import shap\n",
        "explainer_g = shap.TreeExplainer(model_g)\n",
        "shap_values_g = explainer_g.shap_values(X_glaucoma)\n",
        "\n",
        "\n",
        "shap.summary_plot(shap_values_g, X_glaucoma, feature_names=glaucoma_features)\n",
        "\n",
        "\n",
        "explainer_s = shap.TreeExplainer(model_s)\n",
        "shap_values_s = explainer_s.shap_values(X_syndrome)\n",
        "shap.summary_plot(shap_values_s[1], X_syndrome, feature_names=syndrome_features, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values_s[2], X_syndrome, feature_names=syndrome_features, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "wIXW8JSy3Pjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}